<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts | Jiarong Lin</title>
    <link>https://ziv-lin.github.io/post/</link>
      <atom:link href="https://ziv-lin.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    <description>Posts</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Mon, 16 Jan 2023 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://ziv-lin.github.io/media/icon_hu9d99c7745ea620931e335f427cb4032d_148591_512x512_fill_lanczos_center_3.png</url>
      <title>Posts</title>
      <link>https://ziv-lin.github.io/post/</link>
    </image>
    
    <item>
      <title>Gave a talk on &#34;Simultaneous Localization and Mapping with Multi-sensor Fusion&#34; at shenlanxueyuan.com (Audiences: 13,000&#43;).</title>
      <link>https://ziv-lin.github.io/post/shenlang_talk/</link>
      <pubDate>Mon, 16 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://ziv-lin.github.io/post/shenlang_talk/</guid>
      <description>&lt;p&gt;

















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;a href=&#34;https://www.shenlanxueyuan.com/open/course/181&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /media/talks/shenlan_talk_hu79830f466e457db8537b3dc5301565e1_307909_08681b7a266e0c6adf6ff7d4b4f62e5a.webp 400w,
               /media/talks/shenlan_talk_hu79830f466e457db8537b3dc5301565e1_307909_e24e05c6affd727b44ee46e75e49512c.webp 760w,
               /media/talks/shenlan_talk_hu79830f466e457db8537b3dc5301565e1_307909_1200x1200_fit_q100_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://ziv-lin.github.io/media/talks/shenlan_talk_hu79830f466e457db8537b3dc5301565e1_307909_08681b7a266e0c6adf6ff7d4b4f62e5a.webp&#34;
               width=&#34;100%&#34;
               height=&#34;271&#34;
               loading=&#34;lazy&#34; /&gt;&lt;/a&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;



















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;a href=&#34;https://www.shenlanxueyuan.com/open/course/181&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /media/talks/shenlan_talk_ppt_huebbfad1edfa8e198fe68a27ac6a615ca_796799_051bda4df061cd65c8d3307bdc9b803b.webp 400w,
               /media/talks/shenlan_talk_ppt_huebbfad1edfa8e198fe68a27ac6a615ca_796799_6e28a62c7df747759b4dc9216a6ab10a.webp 760w,
               /media/talks/shenlan_talk_ppt_huebbfad1edfa8e198fe68a27ac6a615ca_796799_1200x1200_fit_q100_h2_lanczos.webp 1200w&#34;
               src=&#34;https://ziv-lin.github.io/media/talks/shenlan_talk_ppt_huebbfad1edfa8e198fe68a27ac6a615ca_796799_051bda4df061cd65c8d3307bdc9b803b.webp&#34;
               width=&#34;100%&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; /&gt;&lt;/a&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;1-introduction&#34;&gt;&lt;strong&gt;1. Introduction&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Invited by &lt;a href=&#34;https://www.shenlanxueyuan.com/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;shenlanxueyuan.com&lt;/a&gt;, I give an online talk on &lt;a href=&#34;https://www.shenlanxueyuan.com/open/course/181&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;ldquo;Simultaneous Localization and Mapping with Multi-sensor Fusion (基于多传感器融合的定位和建图系统)&amp;rdquo;&lt;/a&gt;. In this talk, I shared my researches in my Ph.D. studies.&lt;/p&gt;
&lt;h4 id=&#34;ppt-slide&#34;&gt;PPT Slide:&lt;/h4&gt;
&lt;p&gt;&lt;a href=&#34;uploads/Simultaneous_localization_and_mapping_with_Multi-sensor_Fusion.pdf&#34;&gt;Simultaneous_Localization_and_Mapping_with_Multi-sensor_Fusion.pdf&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;2-contents&#34;&gt;&lt;strong&gt;2. Contents&lt;/strong&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;LiDAR(-inertial) SLAM
&lt;ul&gt;
&lt;li&gt;World&amp;rsquo;s first LiDAR odometry and mapping (LOAM) system for solid-state LiDAR (&lt;a href=&#34;https://github.com/hku-mars/loam_livox&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;loam-livox&lt;/strong&gt;&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Tightly-coupled LiDAR-inertial odometry (&lt;a href=&#34;https://github.com/hku-mars/FAST_LIO&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;FAST-LIO&lt;/strong&gt;&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Multi-sensor Fusion (LiDAR-Inertial-Visual)
&lt;ul&gt;
&lt;li&gt;World&amp;rsquo;s first open-source tightly-coupled LiDAR-Inertial-Visual system (&lt;a href=&#34;https://github.com/hku-mars/r2live&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;R&lt;sup&gt;2&lt;/sup&gt;LIVE&lt;/strong&gt;&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Real-time radiance map reconstruction package (&lt;a href=&#34;https://github.com/hku-mars/r3live&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;R&lt;sup&gt;3&lt;/sup&gt;LIVE&lt;/strong&gt;&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Immediate LiDAR localization and meshing Framework (&lt;a href=&#34;https://github.com/hku-mars/ImMesh&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;ImMesh&lt;/strong&gt;&lt;/a&gt;)
&lt;ul&gt;
&lt;li&gt;Introduction to ImMesh, experiments and results.&lt;/li&gt;
&lt;li&gt;Applications based on ImMesh
&lt;ul&gt;
&lt;li&gt;ImMesh for LiDAR point cloud reinforcement&lt;/li&gt;
&lt;li&gt;ImMesh for Rapid, Lossless texture reconstruction&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Release of work &#34;ImMesh: An Immediate LiDAR Localization and Meshing Framework&#34;</title>
      <link>https://ziv-lin.github.io/post/release_of_immesh/</link>
      <pubDate>Fri, 13 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://ziv-lin.github.io/post/release_of_immesh/</guid>
      <description>&lt;h3 id=&#34;1-introduction&#34;&gt;1. Introduction&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;ImMesh&lt;/strong&gt; is a novel LiDAR(-inertial) odometry and meshing framework, which takes advantage of input of LiDAR data, achieving the goal of &lt;strong&gt;simultaneous localization and meshing&lt;/strong&gt; in real-time. ImMesh comprises four tightly-coupled modules: receiver, localization, meshing, and broadcaster. The localization module utilizes the prepossessed sensor data from the receiver, estimates the sensor pose online by registering LiDAR scans to maps, and dynamically grows the map. Then, our meshing module takes the registered LiDAR scan for &lt;strong&gt;incrementally reconstructing the triangle mesh on the fly&lt;/strong&gt;. Finally, the real-time odometry, map, and mesh are published via our broadcaster.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
&lt;img src=&#34;https://github.com/ziv-lin/ImMesh_release/raw/main/pics/overview_v7.jpg&#34; style=&#34;margin: -1px 0px 0px 0px&#34; alt=&#34;video&#34; width=&#34;100%&#34; /&gt;
&lt;/div&gt;
&lt;h4 id=&#34;12-our-accompanying-videos&#34;&gt;1.2 Our accompanying videos&lt;/h4&gt;
&lt;p&gt;Our &lt;strong&gt;accompanying videos&lt;/strong&gt; are now available on &lt;strong&gt;YouTube&lt;/strong&gt; (click below images to open) and &lt;strong&gt;Bilibili&lt;/strong&gt;&lt;sup&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1AG4y1177z&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;1&lt;/a&gt;, &lt;a href=&#34;https://www.bilibili.com/video/BV1Xd4y1j7on/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2&lt;/a&gt;, &lt;a href=&#34;https://www.bilibili.com/video/BV1W8411N7D2&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
&lt;a href=&#34;https://youtu.be/pzT2fMwz428&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://github.com/ziv-lin/ImMesh_release/raw/main/pics/video_cover.jpg&#34; style=&#34;margin: -5px 0px 0px 0px&#34; alt=&#34;video&#34; width=&#34;100%&#34; /&gt;&lt;/a&gt;
&lt;!-- &lt;a href=&#34;https://youtu.be/pzT2fMwz428?t=4&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://github.com/ziv-lin/ImMesh_release/raw/main/pics/video_contents.jpg&#34; alt=&#34;video&#34; width=&#34;100%&#34; /&gt;&lt;/a&gt; --&gt;
&lt;a href=&#34;https://youtu.be/pzT2fMwz428?t=10&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://github.com/ziv-lin/ImMesh_release/raw/main/pics/video_cover_1.jpg&#34; style=&#34;margin: 2px 0px 0px 0px&#34; alt=&#34;video&#34; width=&#34;100%&#34; /&gt;&lt;/a&gt;
&lt;!-- &lt;a href=&#34;https://youtu.be/pzT2fMwz428?t=191&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://github.com/ziv-lin/ImMesh_release/raw/main/pics/video_cover_2.jpg&#34; style=&#34;margin: 2px 0px 0px 0px&#34; alt=&#34;video&#34; width=&#34;100%&#34; /&gt;&lt;/a&gt;
&lt;a href=&#34;https://youtu.be/pzT2fMwz428?t=321&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://github.com/ziv-lin/ImMesh_release/raw/main/pics/video_cover_3.jpg&#34; style=&#34;margin: 2px 0px 0px 0px&#34; alt=&#34;video&#34; width=&#34;100%&#34; /&gt;&lt;/a&gt; --&gt;
&lt;a href=&#34;https://youtu.be/pzT2fMwz428?t=499&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://github.com/ziv-lin/ImMesh_release/raw/main/pics/video_cover_4.jpg&#34; style=&#34;margin: 2px 0px 0px 0px&#34; alt=&#34;video&#34; width=&#34;100%&#34; /&gt;&lt;/a&gt;
&lt;!-- &lt;a href=&#34;https://youtu.be/pzT2fMwz428?t=622&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://github.com/ziv-lin/ImMesh_release/raw/main/pics/video_cover_5.jpg&#34; style=&#34;margin: 2px 0px 0px 0px&#34; alt=&#34;video&#34; width=&#34;100%&#34; /&gt;&lt;/a&gt; --&gt;
&lt;a href=&#34;https://youtu.be/pzT2fMwz428?t=892&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://github.com/ziv-lin/ImMesh_release/raw/main/pics/video_cover_6.jpg&#34; style=&#34;margin: 2px 0px 0px 0px&#34; alt=&#34;video&#34; width=&#34;100%&#34; /&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;h3 id=&#34;2-what-can-immesh-do&#34;&gt;2. What can ImMesh do?&lt;/h3&gt;
&lt;h4 id=&#34;21-simultaneous-lidar-localization-and-mesh-reconstruction-on-the-fly&#34;&gt;2.1 Simultaneous LiDAR localization and mesh reconstruction on the fly&lt;/h4&gt;
&lt;div class=&#34;row&#34;&gt;
&lt;img src=&#34;https://github.com/ziv-lin/ImMesh_release/raw/main/pics/gifs/hku_seq_campus.gif&#34; style=&#34;margin: -2px 0px 0px 0px&#34; alt=&#34;video&#34;   width=&#34;49%&#34; /&gt;
&lt;img src=&#34;https://github.com/ziv-lin/ImMesh_release/raw/main/pics/gifs/hku_seq_main_building.gif&#34; style=&#34;margin: -2px 0px 0px 5px&#34; alt=&#34;video&#34;   width=&#34;49%&#34; /&gt;
&lt;/div&gt;
&lt;h4 id=&#34;22-immesh-for-lidar-point-cloud-reinforement&#34;&gt;2.2 ImMesh for LiDAR point cloud reinforement&lt;/h4&gt;
&lt;div class=&#34;row&#34;&gt;
&lt;img src=&#34;https://github.com/ziv-lin/ImMesh_release/raw/main/pics/gifs/application_1_fov.gif&#34; style=&#34;margin: -2px 0px 0px 0px&#34; alt=&#34;video&#34;  width=&#34;49%&#34; /&gt;
&lt;img src=&#34;https://github.com/ziv-lin/ImMesh_release/raw/main/pics/gifs/application_1_res.gif&#34; style=&#34;margin: -2px 0px 0px 5px&#34; alt=&#34;video&#34;  width=&#34;49%&#34; /&gt;
&lt;/div&gt;
&lt;h4 id=&#34;23-immesh-for-rapid-lossless-texture-reconstruction&#34;&gt;2.3 ImMesh for rapid, lossless texture reconstruction&lt;/h4&gt;
&lt;div class=&#34;row&#34;&gt;
&lt;img src=&#34;https://github.com/ziv-lin/ImMesh_release/raw/main/pics/gifs/application_2_trial_1-0.gif&#34; style=&#34;margin: -2px 0px 0px 0px&#34; alt=&#34;video&#34;   width=&#34;49%&#34; /&gt;
&lt;img src=&#34;https://github.com/ziv-lin/ImMesh_release/raw/main/pics/gifs/application_2_trial_1-1.gif&#34; style=&#34;margin: -2px 2px 0px 2px&#34; width=&#34;49%&#34; /&gt;
&lt;img src=&#34;https://github.com/ziv-lin/ImMesh_release/raw/main/pics/gifs/application_2_trial_2-0.gif&#34; style=&#34;margin: 2px 0px 0px 0px&#34; width=&#34;49%&#34; /&gt;
&lt;img src=&#34;https://github.com/ziv-lin/ImMesh_release/raw/main/pics/gifs/application_2_trial_2-1.gif&#34; style=&#34;margin: 2px 2px 0px 2px&#34; width=&#34;49%&#34; /&gt;
&lt;/div&gt;
&lt;h3 id=&#34;3-contact-us&#34;&gt;3. Contact us&lt;/h3&gt;
&lt;p&gt;If you have any questions about this work, please feel free to contact me &amp;lt;ziv.lin.ljrATgmail.com&amp;gt; and Dr. Fu Zhang &amp;lt;fuzhangAThku.hk&amp;gt; via email.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
